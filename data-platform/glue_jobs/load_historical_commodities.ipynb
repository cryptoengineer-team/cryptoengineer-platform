{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%iam_role arn:aws:iam::212430227630:role/LabRole\n%region us-east-1\n%number_of_workers 2\n\n%idle_timeout 30\n%glue_version 4.0\n%worker_type G.1X",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent iam_role is arn:aws:iam::212430227630:role/LabRole\niam_role has been set to arn:aws:iam::212430227630:role/LabRole.\nPrevious region: us-east-1\nSetting new region to: us-east-1\nRegion is set to: us-east-1\nPrevious number of workers: None\nSetting new number of workers to: 2\nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 30 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%extra_py_files s3://cryptoengineer/gluejobs-py-modules/load.py, s3://cryptoengineer/gluejobs-py-modules/storage.py\n%additional_python_modules yfinance",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "Extra py files to be included:\ns3://cryptoengineer/gluejobs-py-modules/load.py\ns3://cryptoengineer/gluejobs-py-modules/storage.py\nAdditional python modules to be included:\nyfinance\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%load_ext autoreload\n%autoreload 2",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "import sys\nimport boto3\n\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 30\nSession ID: 3c4cf63f-6a07-4a5b-a920-ca77494c104d\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\n--extra-py-files s3://cryptoengineer/gluejobs-py-modules/load.py,s3://cryptoengineer/gluejobs-py-modules/storage.py\n--additional-python-modules yfinance\nWaiting for session 3c4cf63f-6a07-4a5b-a920-ca77494c104d to get into ready status...\nSession 3c4cf63f-6a07-4a5b-a920-ca77494c104d has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## HISTORICAL LOAD",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "markdown",
			"source": "### Load modules",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime, timedelta, timezone\n\nimport load",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Set AWS storage parameters",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "BUCKET_NAME = \"cryptoengineer\"\nPREFIX = \"datalake/bronze/commodities\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Load job parameters",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "glue_client = boto3.client(\"glue\")\n\nif '--WORKFLOW_NAME' in sys.argv and '--WORKFLOW_RUN_ID' in sys.argv:\n    print(\"Running in Glue Workflow\")\n    \n    glue_args = getResolvedOptions(\n        sys.argv, ['WORKFLOW_NAME', 'WORKFLOW_RUN_ID']\n    )\n    \n    print(\"Reading the workflow parameters\")\n    workflow_args = glue_client.get_workflow_run_properties(\n        Name=glue_args['WORKFLOW_NAME'], RunId=glue_args['WORKFLOW_RUN_ID']\n    )[\"RunProperties\"]\n\n    \n    base= workflow_args['base']\n    start_date = workflow_args['start_date']\n    end_date = workflow_args['end_date']\n    symbols = workflow_args['symbols']\n    api_key = workflow_args['api_key']\n\nelse:\n    try:\n        args = getResolvedOptions(sys.argv,\n                                  ['JOB_NAME',\n                                   'base',\n                                   'start_date',\n                                   'end_date',\n                                   'symbols',\n                                   'api_key'])\n        base= args['base']\n        start_date = args['start_date']\n        end_date = args['end_date']\n        symbols = args['symbols']\n        api_key = args['api_key']\n        print(\"Running as Job\")        \n    except:\n        print(\"Running as Notebook\")\n        base= 'USD'\n        start_date = '2023-07-01'\n        end_date = '2024-08-29'\n        symbols = \"GCUSD\"\n        api_key= \"\"\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 35,
			"outputs": [
				{
					"name": "stdout",
					"text": "Running as Notebook\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(\"base: \", base)\nprint(\"Start Date: \", start_date)\nprint(\"End Date: \", end_date)\nprint(\"Symbols: \", symbols)\nprint(\"API Key: \", api_key)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "## Load the historical rates 15min frequency",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df = load.load_historical_freq_rates(base=base,\n                                      start_date=start_date,\n                                      end_date=end_date,\n                                      freq='15min',\n                                      symbol=symbols,\n                                      api_key=api_key,\n                                      source='FMP'\n)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 38,
			"outputs": [
				{
					"name": "stdout",
					"text": "Year:  2023  Month: 7\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  0\nYear:  2023  Month: 8\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  0\nYear:  2023  Month: 8\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  0\nYear:  2023  Month: 9\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  460\nYear:  2023  Month: 10\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  2508\nYear:  2023  Month: 11\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  4203\nYear:  2023  Month: 12\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  6017\nYear:  2024  Month: 1\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  8052\nYear:  2024  Month: 2\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  9974\nYear:  2024  Month: 3\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  11814\nYear:  2024  Month: 4\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  13838\nYear:  2024  Month: 5\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  15919\nYear:  2024  Month: 6\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  17755\nYear:  2024  Month: 7\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  19704\n2024-08\nYear:  2024  Month: 8\nhttps://financialmodelingprep.com/api/v3/historical-chart/15min\nReading month\nLectura API correcta\nLeidos  21704\nCreating the dataframe\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(\"Records: \", len(df))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 39,
			"outputs": [
				{
					"name": "stdout",
					"text": "Records:  21704\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 40,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21704 entries, 0 to 21703\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   date    21704 non-null  object \n 1   open    21704 non-null  float64\n 2   low     21704 non-null  float64\n 3   high    21704 non-null  float64\n 4   close   21704 non-null  float64\n 5   volume  21704 non-null  int64  \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 1017.5+ KB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.head(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 41,
			"outputs": [
				{
					"name": "stdout",
					"text": "                  date    open     low    high   close  volume\n0  2023-09-29 16:45:00  1864.7  1864.6  1865.6  1864.6     755\n1  2023-09-29 16:30:00  1864.8  1864.2  1866.1  1864.8    1095\n2  2023-09-29 16:15:00  1864.4  1864.1  1865.2  1864.9     723\n3  2023-09-29 16:00:00  1864.3  1863.8  1864.5  1864.3    1052\n4  2023-09-29 15:45:00  1866.0  1864.2  1866.2  1864.4    1567\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Set the schema",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "freq='15min'\nsymbol=symbols\nsource='FMP'",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 42,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = load.set_schema_table(df, symbol, source, freq, base)\ndf.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 43,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21704 entries, 0 to 21703\nData columns (total 18 columns):\n #   Column         Non-Null Count  Dtype              \n---  ------         --------------  -----              \n 0   datetime       21704 non-null  object             \n 1   open           21704 non-null  float64            \n 2   low            21704 non-null  float64            \n 3   high           21704 non-null  float64            \n 4   close          21704 non-null  float64            \n 5   volume         21704 non-null  int64              \n 6   year           21704 non-null  object             \n 7   month          21704 non-null  object             \n 8   day            21704 non-null  object             \n 9   time           21704 non-null  object             \n 10  date           21704 non-null  object             \n 11  base_currency  21704 non-null  object             \n 12  source         21704 non-null  object             \n 13  frequency      21704 non-null  object             \n 14  symbol         21704 non-null  object             \n 15  audit_time     21704 non-null  datetime64[ns, UTC]\n 16  load_date      21704 non-null  object             \n 17  type           21704 non-null  object             \ndtypes: datetime64[ns, UTC](1), float64(4), int64(1), object(12)\nmemory usage: 3.0+ MB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Save a backup copy as CSV",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Set the path to the S3 location\npath=f\"s3://{BUCKET_NAME}/historic_bck/GCUSD.csv\"\n# Si no particionamos por symbol\nprint(\"Path:\",path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 44,
			"outputs": [
				{
					"name": "stdout",
					"text": "Path: s3://cryptoengineer/historic_bck/GCUSD.csv\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.to_csv(path, header=True, index=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 45,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Save dataframe to raw in parquet format",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Set the path to the S3 location\npath=f\"s3://{BUCKET_NAME}/{PREFIX}\"\n# Si no particionamos por symbol\nprint(\"Path:\",path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 46,
			"outputs": [
				{
					"name": "stdout",
					"text": "Path: s3://cryptoengineer/datalake/raw/commodities\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "(\n    spark.createDataFrame(df)\n    .repartition(\"load_date\")\n    .write\n    .format(\"parquet\")\n    .mode(\"append\")\n    .partitionBy(['load_date'])\n    .save(path)\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 47,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}