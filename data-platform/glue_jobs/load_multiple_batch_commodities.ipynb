{"metadata":{"kernelspec":{"name":"glue_pyspark","display_name":"Glue PySpark","language":"python"},"language_info":{"name":"Python_Glue_Session","mimetype":"text/x-python","codemirror_mode":{"name":"python","version":3},"pygments_lexer":"python3","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AWS Glue Job - Load Forex data to Bronze Stage from API source","metadata":{"editable":true,"trusted":true}},{"cell_type":"markdown","source":"## Set the Glue session parameters\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"%iam_role arn:aws:iam::212430227630:role/LabRole\n%region us-east-1\n%number_of_workers 2\n\n%idle_timeout 30\n%glue_version 4.0\n%worker_type G.1X\n\n%%configure \n{\n  \"--enable-metrics\": \"true\",\n  \"--enable-observability-metrics\": \"true\"\n}","metadata":{"trusted":true,"editable":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent iam_role is arn:aws:iam::212430227630:role/LabRole\niam_role has been set to arn:aws:iam::212430227630:role/LabRole.\nPrevious region: us-east-1\nSetting new region to: us-east-1\nRegion is set to: us-east-1\nPrevious number of workers: None\nSetting new number of workers to: 2\nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 30 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nThe following configurations have been updated: {'--enable-metrics': 'true', '--enable-observability-metrics': 'true'}\n","output_type":"stream"}]},{"cell_type":"code","source":"%extra_py_files s3://cryptoengineer/gluejobs-py-modules/load.py, s3://cryptoengineer/gluejobs-py-modules/storage.py\n%additional_python_modules yfinance","metadata":{"trusted":true,"tags":[]},"execution_count":11,"outputs":[{"name":"stdout","text":"Extra py files to be included:\ns3://cryptoengineer/gluejobs-py-modules/load.py\ns3://cryptoengineer/gluejobs-py-modules/storage.py\nAdditional python modules to be included:\nyfinance\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##  Set up and start your interactive session.\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true,"tags":[]},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import sys\nimport boto3\n\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)","metadata":{"trusted":true,"editable":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 30\nSession ID: 8b861921-2460-4817-be65-f3e8435ddfb9\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\n--enable-metrics true\n--enable-observability-metrics true\n--extra-py-files s3://cryptoengineer/gluejobs-py-modules/load.py,s3://cryptoengineer/gluejobs-py-modules/storage.py\n--additional-python-modules yfinance\nWaiting for session 8b861921-2460-4817-be65-f3e8435ddfb9 to get into ready status...\nSession 8b861921-2460-4817-be65-f3e8435ddfb9 has been created.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Batch Load - COMMODITIES\n\n### Load the libraries and dependencies","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"from datetime import datetime, timedelta, timezone\nimport pyspark.sql.functions as F\n\nimport pandas as pd\nimport load","metadata":{"trusted":true,"tags":[]},"execution_count":2,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Set AWS Storage parameters\n","metadata":{}},{"cell_type":"code","source":"BUCKET_NAME = \"cryptoengineer\"\nPREFIX = \"datalake/bronze/commodities\"","metadata":{"trusted":true,"tags":[]},"execution_count":3,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load job parameters","metadata":{}},{"cell_type":"code","source":"glue_client = boto3.client(\"glue\")\n# Check if params come from a GLUE workflow\nif '--WORKFLOW_NAME' in sys.argv and '--WORKFLOW_RUN_ID' in sys.argv:\n    print(\"Running in Glue Workflow\")\n    \n    glue_args = getResolvedOptions(\n        sys.argv, ['WORKFLOW_NAME', 'WORKFLOW_RUN_ID']\n    )\n    \n    print(\"Reading the workflow parameters\")\n    workflow_args = glue_client.get_workflow_run_properties(\n        Name=glue_args['WORKFLOW_NAME'], RunId=glue_args['WORKFLOW_RUN_ID']\n    )[\"RunProperties\"]\n\n    \n    base= workflow_args['base']\n    time_frame = int(workflow_args['time_frame'])\n    freq= workflow_args['freq']\n    symbols = workflow_args['symbols']\n    api_key = workflow_args['api_key']\n\nelse:\n    # Check if params come from a Glue Job    \n    try:\n        args = getResolvedOptions(sys.argv,\n                                  ['JOB_NAME',\n                                   'base',\n                                   'time_frame',\n                                   'freq',\n                                   'symbols',\n                                   'api_key'])\n        base= args['base']\n        time_frame = int(args['time_frame'])\n        freq = args['freq']\n        symbols = args['symbols']\n        api_key = args['api_key']\n        print(\"Running as Job\")        \n    except:\n        print(\"Running as Notebook\")\n        base = \"USD\"\n        time_frame = 408 #48\n        freq= '15min' #'1day'\n        symbols = \"CLUSD,GCUSD,NGUSD\"\n        api_key = \"\"","metadata":{"trusted":true,"editable":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Running as Notebook\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"base: \", base)\nprint(\"Time Frame: \", time_frame)\nprint(\"Frequency: \", freq)\nprint(\"Symbols: \", symbols)\nprint(\"API Key: \", api_key)","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Set the start and end dates for the data you want to load","metadata":{"tags":[]}},{"cell_type":"code","source":"# Start date\nstart_date = (datetime.utcnow() - timedelta(hours=time_frame)).strftime(\"%Y-%m-%d\")\nend_date = datetime.utcnow().strftime(\"%Y-%m-%d\")\n\nprint(\"Start date; \",start_date,\" End date: \",end_date)","metadata":{"trusted":true,"tags":[]},"execution_count":7,"outputs":[{"name":"stdout","text":"Start date;  2024-09-07  End date:  2024-09-24\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Read max date loaded from INFO table","metadata":{}},{"cell_type":"code","source":"PREFIX_INFO_TABLE='datalake/gold/commodities'\npath=f\"s3://{BUCKET_NAME}/{PREFIX_INFO_TABLE}\"\nprint(\"Path:\", path)","metadata":{"trusted":true,"tags":[]},"execution_count":8,"outputs":[{"name":"stdout","text":"Path: s3://cryptoengineer/datalake/gold/commodities\n","output_type":"stream"}]},{"cell_type":"code","source":"df_max_dates = (\n    spark\n    .read\n    .parquet(path)\n    .filter(F.col(\"stage\")=='bronze')\n    .select('symbol','base_currency','frequencies','end_datetime')\n    .toPandas()\n)","metadata":{"trusted":true,"tags":[]},"execution_count":9,"outputs":[{"name":"stdout","text":"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n  series = series.astype(t, copy=False)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_max_dates.head(10)","metadata":{"trusted":true,"tags":[]},"execution_count":21,"outputs":[{"name":"stdout","text":"  symbol base_currency frequencies        end_datetime\n0  BZUSD           USD       15min 2024-09-24 11:00:00\n1  BZUSD           USD        1day 2024-09-24 00:00:00\n2  CLUSD           USD       15min 2024-09-06 16:45:00\n3  CLUSD           USD        1day 2024-09-06 00:00:00\n4  GCUSD           USD       15min 2024-09-06 16:45:00\n5  GCUSD           USD        1day 2024-09-06 00:00:00\n6  NGUSD           USD       15min 2024-09-06 16:45:00\n7  NGUSD           USD        1day 2024-09-06 00:00:00\n","output_type":"stream"}]},{"cell_type":"code","source":"df_max_dates.info()","metadata":{"trusted":true,"tags":[]},"execution_count":11,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8 entries, 0 to 7\nData columns (total 4 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   symbol         8 non-null      object        \n 1   base_currency  8 non-null      object        \n 2   frequencies    8 non-null      object        \n 3   end_datetime   8 non-null      datetime64[ns]\ndtypes: datetime64[ns](1), object(3)\nmemory usage: 384.0+ bytes\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the historical commodities- 15min frequency","metadata":{}},{"cell_type":"markdown","source":"Set some config values","metadata":{}},{"cell_type":"code","source":"type='COMMODITIES'\nsource='FMP'","metadata":{"trusted":true,"tags":[]},"execution_count":12,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"if freq == '15min':\n    print(\"Reading historical data by frequency\")\n    df= pd.DataFrame()\n    for symbol in symbols.split(\",\"):\n        print(\"Loading: \", symbol)\n        symbol_df = load.load_batch_freq_rates(base=base,\n                                              start_date=start_date,\n                                              end_date=end_date,\n                                              freq=freq,\n                                              symbol=symbol,\n                                              api_key=api_key,\n                                              source=source\n        )\n        print(\"Records loaded: \", len(symbol_df))        \n        # Get the max date time already loaded \n        max_datetime=df_max_dates[(df_max_dates['symbol'] ==symbol) & (df_max_dates['base_currency'] ==base) \n                              & (df_max_dates['frequencies'] ==freq)]['end_datetime'].max()\n        # Extract only the new data\n        symbol_df = symbol_df[pd.to_datetime(symbol_df['date']) > max_datetime]\n        print(\"New records: \", len(symbol_df))\n        \n        # Complete the table schema \n        if len(symbol_df)>0:\n            symbol_df = load.set_schema_table(symbol_df, symbol, source, freq, base, type)\n            print(\"Records: \", len(symbol_df))\n            df = pd.concat([df, symbol_df])\n        else:\n            print(\"No data for: \", symbol)\n\nelse:\n    print(\"Reading daily historical data\")\n    df= pd.DataFrame()\n    for symbol in symbols.split(\",\"):\n        print(\"Loading: \", symbol)\n        symbol_df = load.load_historical_rates(base=base,\n                                              start_date=start_date,\n                                              end_date=end_date,\n                                              symbol=symbol,\n                                              api_key=api_key,\n                                              source=source\n        )\n        print(\"Records loaded: \", len(symbol_df))        \n        # Get the max date time already loaded \n        max_datetime=df_max_dates[(df_max_dates['symbol'] ==symbol) & (df_max_dates['base_currency'] ==base) \n                                  & (df_max_dates['frequencies'] ==freq)]['end_datetime'].max()\n        # Extract only the new data\n        symbol_df = symbol_df[pd.to_datetime(symbol_df['date']) > max_datetime]\n        print(\"New records: \", len(symbol_df))\n        \n        # Complete the table schema \n        if len(symbol_df)>0:        \n            symbol_df = load.set_schema_table(symbol_df, symbol, source, freq, base, type)\n            print(\"Records: \", len(symbol_df))\n            df = pd.concat([df, symbol_df])\n        else:\n            print(\"No data for: \", symbol)\n","metadata":{"trusted":true,"tags":[]},"execution_count":22,"outputs":[{"name":"stdout","text":"Reading daily historical data\nLoading:  CLUSD\nhttps://financialmodelingprep.com/api/v3/historical-price-full\nhttps://financialmodelingprep.com/api/v3/historical-price-full/CLUSD?apikey=xGFdE9Ydrcr1oCDJiCjHiZnkqUnQnjaH\nLectura API correcta\nRecords loaded:  15\nNew records:  15\nRecords:  15\nLoading:  GCUSD\nhttps://financialmodelingprep.com/api/v3/historical-price-full\nhttps://financialmodelingprep.com/api/v3/historical-price-full/GCUSD?apikey=xGFdE9Ydrcr1oCDJiCjHiZnkqUnQnjaH\nLectura API correcta\nRecords loaded:  15\nNew records:  15\nRecords:  15\nLoading:  NGUSD\nhttps://financialmodelingprep.com/api/v3/historical-price-full\nhttps://financialmodelingprep.com/api/v3/historical-price-full/NGUSD?apikey=xGFdE9Ydrcr1oCDJiCjHiZnkqUnQnjaH\nLectura API correcta\nRecords loaded:  15\nNew records:  15\nRecords:  15\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Records: \", len(df))","metadata":{"trusted":true,"tags":[]},"execution_count":23,"outputs":[{"name":"stdout","text":"Records:  45\n","output_type":"stream"}]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"tags":[]},"execution_count":24,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 45 entries, 0 to 14\nData columns (total 25 columns):\n #   Column            Non-Null Count  Dtype              \n---  ------            --------------  -----              \n 0   datetime          45 non-null     object             \n 1   open              45 non-null     float64            \n 2   high              45 non-null     float64            \n 3   low               45 non-null     float64            \n 4   close             45 non-null     float64            \n 5   adjClose          45 non-null     float64            \n 6   volume            45 non-null     int64              \n 7   unadjustedVolume  45 non-null     int64              \n 8   change            45 non-null     float64            \n 9   changePercent     45 non-null     float64            \n 10  vwap              45 non-null     float64            \n 11  label             45 non-null     object             \n 12  changeOverTime    45 non-null     float64            \n 13  year              45 non-null     object             \n 14  month             45 non-null     object             \n 15  day               45 non-null     object             \n 16  time              45 non-null     object             \n 17  date              45 non-null     object             \n 18  base_currency     45 non-null     object             \n 19  source            45 non-null     object             \n 20  frequency         45 non-null     object             \n 21  symbol            45 non-null     object             \n 22  audit_time        45 non-null     datetime64[ns, UTC]\n 23  load_date         45 non-null     object             \n 24  type              45 non-null     object             \ndtypes: datetime64[ns, UTC](1), float64(9), int64(2), object(13)\nmemory usage: 9.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.tail(15)","metadata":{"trusted":true,"tags":[]},"execution_count":25,"outputs":[{"name":"stdout","text":"      datetime   open  ...   load_date         type\n0   2024-09-24  2.634  ...  2024-09-24  COMMODITIES\n1   2024-09-23  2.462  ...  2024-09-24  COMMODITIES\n2   2024-09-22  2.462  ...  2024-09-24  COMMODITIES\n3   2024-09-20  2.358  ...  2024-09-24  COMMODITIES\n4   2024-09-19  2.288  ...  2024-09-24  COMMODITIES\n5   2024-09-18  2.312  ...  2024-09-24  COMMODITIES\n6   2024-09-17  2.391  ...  2024-09-24  COMMODITIES\n7   2024-09-16  2.298  ...  2024-09-24  COMMODITIES\n8   2024-09-15  2.298  ...  2024-09-24  COMMODITIES\n9   2024-09-13  2.363  ...  2024-09-24  COMMODITIES\n10  2024-09-12  2.286  ...  2024-09-24  COMMODITIES\n11  2024-09-11  2.236  ...  2024-09-24  COMMODITIES\n12  2024-09-10  2.149  ...  2024-09-24  COMMODITIES\n13  2024-09-09  2.220  ...  2024-09-24  COMMODITIES\n14  2024-09-08  2.220  ...  2024-09-24  COMMODITIES\n\n[15 rows x 25 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Append the batch data to RAW table","metadata":{}},{"cell_type":"markdown","source":"Set the destination raw table","metadata":{}},{"cell_type":"code","source":"path=f\"s3://{BUCKET_NAME}/{PREFIX}\"\nprint(\"Path:\",path)","metadata":{"trusted":true,"tags":[]},"execution_count":26,"outputs":[{"name":"stdout","text":"Path: s3://cryptoengineer/datalake/bronze/commodities\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Save data to datalake, bronze stage, in parquet format and partitioned by load_date","metadata":{}},{"cell_type":"code","source":"if len(df)>0:\n    print(\"Saving data to: \", path)    \n    (\n        spark.createDataFrame(df)\n        .repartition(\"load_date\")\n        .write\n        .format(\"parquet\")\n        .mode(\"append\")\n        .partitionBy(['load_date'])\n        .save(path)\n    )","metadata":{"trusted":true,"tags":[]},"execution_count":27,"outputs":[{"name":"stdout","text":"Saving data to:  s3://cryptoengineer/datalake/bronze/commodities\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}