{"metadata":{"kernelspec":{"name":"glue_pyspark","display_name":"Glue PySpark","language":"python"},"language_info":{"name":"Python_Glue_Session","mimetype":"text/x-python","codemirror_mode":{"name":"python","version":3},"pygments_lexer":"python3","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CARGA HISTÓRICA DE DATOS\n##### El presente notebook tiene como objeto procesar los ficheros .csv que KRAKEN pone a disposición pública con periodicidad trimestral, consolidando así la información que se genera en su plataforma.\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"markdown","source":"####  Run this cell to set up and start your interactive session.\n","metadata":{"editable":true,"trusted":true}},{"cell_type":"code","source":"#%help","metadata":{"trusted":true,"editable":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%region us-east-1\n%number_of_workers 2\n%idle_timeout 30\n%worker_type G.1X\n%glue_version 4.0\n\nBUCKET = 'cryptoengineer'","metadata":{"trusted":true,"editable":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nPrevious region: us-east-1\nSetting new region to: us-east-1\nRegion is set to: us-east-1\nPrevious number of workers: None\nSetting new number of workers to: 2\nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 30 minutes.\nPrevious worker type: None\nSetting new worker type to: G.1X\nSetting Glue version to: 4.0\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 30\nSession ID: 497b675d-6627-4dcf-bbb0-62682d1ca4dc\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session 497b675d-6627-4dcf-bbb0-62682d1ca4dc to get into ready status...\nSession 497b675d-6627-4dcf-bbb0-62682d1ca4dc has been created.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Importación de librerías necesarias\nfrom pyspark.sql.types import StructField, StructType, StringType, DoubleType, IntegerType, TimestampType, DateType\nfrom pyspark.sql.functions import col, from_unixtime, lit, regexp_replace, current_date, min as spark_min, max as spark_max\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nimport boto3\nimport os\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)","metadata":{"trusted":true,"tags":[]},"execution_count":4,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Defino función para determinar los ficheros a procesar\ndef list_s3_files(bucket_name, folder_prefix):\n    s3 = boto3.client('s3')\n    paginator = s3.get_paginator('list_objects_v2')\n    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=folder_prefix)\n    \n    files = []\n    for page in page_iterator:\n        if 'Contents' in page:\n            for obj in page['Contents']:\n                # Check if the object is a file and not a directory\n                if not obj['Key'].endswith('/'):\n                    # Extract the file name from the full S3 key\n                    file_name = os.path.basename(obj['Key'])\n                    files.append(file_name)\n    return files","metadata":{"trusted":true,"tags":[]},"execution_count":5,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lectura de ficheros CSV a procesar\nfiles = list_s3_files(BUCKET, 'datalake/historic_data/cryptos')\n\nprint('Los ficheros a procesar son: ')\nfor file in files:\n    print(file)","metadata":{"trusted":true,"tags":[]},"execution_count":6,"outputs":[{"name":"stdout","text":"Los ficheros a procesar son: \n1INCHUSD_15.csv\nXBTUSDC_15.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creación del esquema \nhistoric_schema = StructType([\n    StructField('TIMESTAMP', StringType(), True),\n    StructField('OPEN', DoubleType(), True),\n    StructField('HIGH', DoubleType(), True),\n    StructField('LOW', DoubleType(), True),\n    StructField('CLOSE', DoubleType(), True),\n    StructField('VOLUME', DoubleType(), True),\n    StructField('TRADES', IntegerType(), True),\n    StructField('ORIGIN', StringType(), True),\n    StructField('LOAD_DATE', DateType(), True),\n    StructField('SYMBOL', StringType(), True),\n    StructField('DATETIME', TimestampType(), True),\n    StructField('YEAR', IntegerType(), True)\n])\n\n#Creación del DF de destino\nhistoric_df = spark.createDataFrame([], historic_schema)","metadata":{"trusted":true,"tags":[]},"execution_count":7,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Iteración a través de todos los ficheros \nfor file in files:\n    print('Procesado el fichero: ' + file)\n    #Lectura del fichero\n    file_df = (\n        spark.read\n        .format(\"csv\")\n        .schema(historic_schema)\n        .option('header', 'false')\n        .load('s3://' + BUCKET + '/datalake/historic_data/cryptos/' + file)\n\n        #Transformaciones básicas\n        .withColumn('origin', lit('historic'))\n        .withColumn('load_date', current_date())\n        .withColumn('symbol', regexp_replace(lit(file), '_15.csv', ''))\n        .withColumn('datetime', from_unixtime(col('timestamp')).cast('timestamp'))\n        .withColumn('year', col('datetime').substr(0, 4).cast('int'))\n\n    )\n    historic_df = historic_df.unionAll(file_df)","metadata":{"trusted":true,"tags":[]},"execution_count":8,"outputs":[{"name":"stdout","text":"Procesado el fichero: 1INCHUSD_15.csv\nProcesado el fichero: XBTUSDC_15.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"historic_df.printSchema()","metadata":{"trusted":true,"tags":[]},"execution_count":9,"outputs":[{"name":"stdout","text":"root\n |-- TIMESTAMP: string (nullable = true)\n |-- OPEN: double (nullable = true)\n |-- HIGH: double (nullable = true)\n |-- LOW: double (nullable = true)\n |-- CLOSE: double (nullable = true)\n |-- VOLUME: double (nullable = true)\n |-- TRADES: integer (nullable = true)\n |-- ORIGIN: string (nullable = true)\n |-- LOAD_DATE: date (nullable = true)\n |-- SYMBOL: string (nullable = true)\n |-- DATETIME: timestamp (nullable = true)\n |-- YEAR: integer (nullable = true)\n","output_type":"stream"}]},{"cell_type":"code","source":"historic_df.show(5)","metadata":{"trusted":true,"tags":[]},"execution_count":10,"outputs":[{"name":"stdout","text":"+----------+-----+-----+-----+-----+-------------+------+--------+----------+--------+-------------------+----+\n| TIMESTAMP| OPEN| HIGH|  LOW|CLOSE|       VOLUME|TRADES|  ORIGIN| LOAD_DATE|  SYMBOL|           DATETIME|YEAR|\n+----------+-----+-----+-----+-----+-------------+------+--------+----------+--------+-------------------+----+\n|1628609400|2.965|3.121|2.764|2.776|6725.61545935|    33|historic|2024-08-23|1INCHUSD|2021-08-10 15:30:00|2021|\n|1628610300|2.793|  2.8| 2.77| 2.77|1306.77452192|    13|historic|2024-08-23|1INCHUSD|2021-08-10 15:45:00|2021|\n|1628611200|2.756|2.833|2.756| 2.76|4855.65736797|    17|historic|2024-08-23|1INCHUSD|2021-08-10 16:00:00|2021|\n|1628612100|2.748|2.754|2.748|2.754|      29.6403|     3|historic|2024-08-23|1INCHUSD|2021-08-10 16:15:00|2021|\n|1628613000| 2.69|2.708| 2.69|2.699|    276.09198|     4|historic|2024-08-23|1INCHUSD|2021-08-10 16:30:00|2021|\n+----------+-----+-----+-----+-----+-------------+------+--------+----------+--------+-------------------+----+\nonly showing top 5 rows\n","output_type":"stream"}]},{"cell_type":"code","source":"#Persistencia de datos\n(\n    historic_df\n        .write\n        .format('parquet')\n        #.partitionBy('symbol','year')\n        .partitionBy('LOAD_DATE')\n        .mode('append')\n        .save('s3://' + BUCKET + '/datalake/bronze/cryptos')\n)\n\nprint('Datos guardados en s3://' + BUCKET + '/datalake/bronze/cryptos')","metadata":{"trusted":true,"tags":[]},"execution_count":6,"outputs":[{"name":"stdout","text":"Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 30\nSession ID: 497b675d-6627-4dcf-bbb0-62682d1ca4dc\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\n","output_type":"stream"},{"name":"stderr","text":"Following exception encountered while creating session: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=497b675d-6627-4dcf-bbb0-62682d1ca4dc \n\nError message: Session already created, sessionId=497b675d-6627-4dcf-bbb0-62682d1ca4dc \n\nTraceback (most recent call last):\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/aws_glue_interactive_sessions_kernel/glue_kernel_utils/KernelGateway.py\", line 100, in create_session\n    response = self.glue_client.create_session(\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 553, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 1009, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.AlreadyExistsException: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=497b675d-6627-4dcf-bbb0-62682d1ca4dc\nException encountered while creating session: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=497b675d-6627-4dcf-bbb0-62682d1ca4dc \nTraceback (most recent call last):\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/aws_glue_interactive_sessions_kernel/glue_kernel_base/BaseKernel.py\", line 170, in do_execute\n    self.create_session()\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/aws_glue_interactive_sessions_kernel/glue_kernel_base/BaseKernel.py\", line 611, in create_session\n    response = self.kernel_gateway.create_session(\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/aws_glue_interactive_sessions_kernel/glue_kernel_utils/KernelGateway.py\", line 100, in create_session\n    response = self.glue_client.create_session(\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 553, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \"/home/jupyter-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 1009, in _make_api_call\n    raise error_class(parsed_response, operation_name)\nbotocore.errorfactory.AlreadyExistsException: An error occurred (AlreadyExistsException) when calling the CreateSession operation: Session already created, sessionId=497b675d-6627-4dcf-bbb0-62682d1ca4dc\n","output_type":"stream"}]}]}