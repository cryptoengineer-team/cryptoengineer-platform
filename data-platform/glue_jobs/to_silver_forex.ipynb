{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%iam_role arn:aws:iam::212430227630:role/LabRole\n%region us-east-1\n%number_of_workers 2\n\n%idle_timeout 30\n%glue_version 4.0\n%worker_type G.1X",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent iam_role is arn:aws:iam::212430227630:role/LabRole\niam_role has been set to arn:aws:iam::212430227630:role/LabRole.\nPrevious region: us-east-1\nSetting new region to: us-east-1\nRegion is set to: us-east-1\nPrevious number of workers: None\nSetting new number of workers to: 2\nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 30 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%load_ext autoreload\n%autoreload 2",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "import sys\nimport boto3\n\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 30\nSession ID: 1d6ff7e8-85b3-4a6e-8106-76cac3db6d51\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session 1d6ff7e8-85b3-4a6e-8106-76cac3db6d51 to get into ready status...\nSession 1d6ff7e8-85b3-4a6e-8106-76cac3db6d51 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Save Raw data to Silver - FOREX\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime, timedelta, timezone\n\nimport pyspark.sql.functions as F",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Set AWS Storage parameters\n",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "BUCKET_NAME = \"cryptoengineer\"\nPREFIX_BRONZE = \"datalake/bronze/forex\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Load job parameters",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "glue_client = boto3.client(\"glue\")\n\nif '--WORKFLOW_NAME' in sys.argv and '--WORKFLOW_RUN_ID' in sys.argv:\n    print(\"Running in Glue Workflow\")\n    \n    glue_args = getResolvedOptions(\n        sys.argv, ['WORKFLOW_NAME', 'WORKFLOW_RUN_ID']\n    )\n    \n    print(\"Reading the workflow parameters\")\n    workflow_args = glue_client.get_workflow_run_properties(\n        Name=glue_args['WORKFLOW_NAME'], RunId=glue_args['WORKFLOW_RUN_ID']\n    )[\"RunProperties\"]\n\n    \n    time_frame = int(workflow_args['time_frame'])\n    symbols = workflow_args['symbols']\n\nelse:\n    try:\n        print(\"Running as Job\")\n        args = getResolvedOptions(sys.argv,\n                                  ['JOB_NAME',\n                                   'time_frame',\n                                   'symbols'\n                                   ])\n\n        time_frame = int(args['time_frame'])\n        symbols = args['symbols']\n    except:\n        time_frame = 24\n        symbols = \"USDEUR\"\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Running as Job\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(\"Time Frame: \", time_frame)\nprint(\"Symbols: \", symbols)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "Time Frame:  120\nSymbols:  USDEUR\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Set the start and end dates for the data you want to load",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "# Start date\nstart_date = (datetime.utcnow() - timedelta(hours=time_frame)).strftime(\"%Y-%m-%d\")\nend_date = datetime.utcnow().strftime(\"%Y-%m-%d\")\n\nprint(\"Start date; \",start_date,\" End date: \",end_date)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "Start date;  2024-08-28  End date:  2024-09-02\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Load the Bronze/Raw data for the time frame and symbol",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "path=f\"s3://{BUCKET_NAME}/{PREFIX_BRONZE}\"\nprint(\"Path:\",path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "Path: s3://cryptoengineer/datalake/raw/forex\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df= (\n    spark\n    .read\n    .parquet(path)\n    .filter(F.col(\"load_date\").between(start_date, end_date))\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(\"Records: \", df.count())",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "Records:  742890\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------------------+-------+-------+-------+-------+------+----+-----+---+--------+----------+-------------+------+---------+------+--------------------+-----+----------+\n|           datetime|   open|    low|   high|  close|volume|year|month|day|    time|      date|base_currency|source|frequency|symbol|          audit_time| type| load_date|\n+-------------------+-------+-------+-------+-------+------+----+-----+---+--------+----------+-------------+------+---------+------+--------------------+-----+----------+\n|2024-09-01 19:45:00|0.90537| 0.9051|0.90543| 0.9051|   301|2024|   09| 01|19:45:00|2024-09-01|          USD|   FMP|    15min|USDEUR|2024-09-02 00:01:...|FOREX|2024-09-02|\n|2024-09-01 19:30:00|0.90526|  0.905|0.90538|0.90534|   285|2024|   09| 01|19:30:00|2024-09-01|          USD|   FMP|    15min|USDEUR|2024-09-02 00:01:...|FOREX|2024-09-02|\n|2024-09-01 19:15:00|0.90517|0.90517|0.90537|0.90529|   274|2024|   09| 01|19:15:00|2024-09-01|          USD|   FMP|    15min|USDEUR|2024-09-02 00:01:...|FOREX|2024-09-02|\n|2024-09-01 19:00:00|0.90524|0.90515|0.90534|0.90516|   268|2024|   09| 01|19:00:00|2024-09-01|          USD|   FMP|    15min|USDEUR|2024-09-02 00:01:...|FOREX|2024-09-02|\n|2024-09-01 18:45:00|0.90503|0.90495|0.90529|0.90526|   160|2024|   09| 01|18:45:00|2024-09-01|          USD|   FMP|    15min|USDEUR|2024-09-02 00:01:...|FOREX|2024-09-02|\n+-------------------+-------+-------+-------+-------+------+----+-----+---+--------+----------+-------------+------+---------+------+--------------------+-----+----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- datetime: string (nullable = true)\n |-- open: double (nullable = true)\n |-- low: double (nullable = true)\n |-- high: double (nullable = true)\n |-- close: double (nullable = true)\n |-- volume: long (nullable = true)\n |-- year: string (nullable = true)\n |-- month: string (nullable = true)\n |-- day: string (nullable = true)\n |-- time: string (nullable = true)\n |-- date: string (nullable = true)\n |-- base_currency: string (nullable = true)\n |-- source: string (nullable = true)\n |-- frequency: string (nullable = true)\n |-- symbol: string (nullable = true)\n |-- audit_time: timestamp (nullable = true)\n |-- type: string (nullable = true)\n |-- load_date: date (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Remove and filter Rows",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# To check duplicates\n\"\"\"\n(\n    df\n    .groupBy('symbol','year','datetime','source','frequency','type')\n    .count().alias('count')\n    .filter(F.col('count') > 1)\n    .show()\n)\n\"\"\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------+----+--------+------+---------+----+-----+\n|symbol|year|datetime|source|frequency|type|count|\n+------+----+--------+------+---------+----+-----+\n+------+----+--------+------+---------+----+-----+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = (\n    df\n    .dropDuplicates(['symbol','year','datetime','source','frequency','type'])\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(\"After dropDuplicates: \", df.count())",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "After dropDuplicates:  730420\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Checking correct values",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "code",
			"source": "\"\"\"\n(\n    df\n    .groupBy('source','type','symbol','year','frequency')\n    .count().alias('count')\n    #.filter(F.col('count') > 1)\n    .show()\n)\n\"\"\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "## Append the batch data to RAW table",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "Set the destination raw table",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "BUCKET_NAME = \"cryptoengineer\"\nPREFIX_SILVER = \"datalake/silver/forex\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 29,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "path=f\"s3://{BUCKET_NAME}/{PREFIX_SILVER}\"\nprint(\"Path:\",path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "Path: s3://cryptoengineer/datalake/silver/forex\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "(\n    df\n    .repartition(\"year\")\n    .write\n    .format(\"parquet\")\n    .mode(\"append\")\n    .partitionBy(['symbol','year'])\n    .save(path)\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}