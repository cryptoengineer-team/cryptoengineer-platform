{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carga de las librerías y clases que vamos a utilizar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37206039",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def eval_model(model=None, StartDate='2024-09-21 00:00:00', EndDate='2024-01-01 00:00:00'):\n",
    "\n",
    "    # Autenticación del usuario para uso de la librería cryptoengineersdk\n",
    "    user_token = {\n",
    "        \"user\": \"hector\",\n",
    "        \"token\": \"a9agHyfg5478GfufUfj98534fs4gHh89Ig7v6fG89kJy7U5f5FFhjU88\"\n",
    "    }\n",
    "    \n",
    "    StartDate = datetime.strptime(StartDate, '%Y-%m-%d %H:%M:%S') \n",
    "    EndDate = datetime.strptime(EndDate, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Parámetros para la obtención de la moneda cuyos precios han de predecirse\n",
    "    table_name = 'silver_t_cryptos'\n",
    "    symbol = 'XBTUSD'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_crypto = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "\n",
    "    table_name = 'silver_t_indices'\n",
    "    symbol = 'SP500'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_SP500 = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "    \n",
    "    table_name = 'silver_t_indices'\n",
    "    symbol = 'Nikkei225'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_Nikkei = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "\n",
    "    table_name = 'silver_t_indices'\n",
    "    symbol = 'IBEX35'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_IBEX35 = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "\n",
    "    table_name = 'silver_t_indices'\n",
    "    symbol = 'Nasdaq'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_Nasdaq = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "    \n",
    "    table_name = 'silver_t_indices'\n",
    "    symbol = 'DAX'\n",
    "    FI = StartDate.year\n",
    "    FF = EndDate.year\n",
    "    # Carga de la información sobre la criptomoneda que ha de predecirse\n",
    "    df_DAX = ce.reader(user_token, table_name, symbol, FI, FF)\n",
    "\n",
    "    # Definición de las variables para recoger los activos e indicadores cuyas cotizaciones se rescatarán de la base de datos  \n",
    "    crypto_list = [\"XBTUSD\", \"ETHUSD\", \"LINKUSD\", \"XDGUSD\"]\n",
    "\n",
    "    def load_crypto(df, crypto_file):\n",
    "        \n",
    "        # Definición del título de las columnas\n",
    "        columns_names = [\n",
    "            \"Base_currency\",\n",
    "            \"Type\",\n",
    "            \"DateTime\",\n",
    "            \"Date\",\n",
    "            \"Time\",\n",
    "            \"Frequency\",\n",
    "            \"Month\",\n",
    "            \"Day\",\n",
    "            f\"{crypto_file}_Open\",\n",
    "            f\"{crypto_file}_High\",\n",
    "            f\"{crypto_file}_Low\",\n",
    "            f\"{crypto_file}_Close\", \n",
    "            f\"{crypto_file}_Volume_USD\", \n",
    "            f\"{crypto_file}_Trades\",\n",
    "            \"Audit_Time\",\n",
    "            \"Symbol\",\n",
    "            \"Year\",\n",
    "        ]\n",
    "      \n",
    "        # Añadir el nombre de las columnas al dataset\n",
    "        df.columns = columns_names\n",
    "        \n",
    "        # Seleccionar únicamente las columnas con las que vamos a trabajar: una columna de fecha y otra columna con el precio de cierre para cada período temporal.\n",
    "        df = df[[\"DateTime\", f\"{crypto_file}_Close\"]]\n",
    "        \n",
    "        # Eliminar primera fila, correspondiente al encabezado existente en la tabla por defecto, que contiene nombres de columna inadecuados para nuestra tarea.\n",
    "        df = df.drop(index=0).reset_index(drop=True)\n",
    "        \n",
    "        # Convertir en formato fecha la columna \"DateTime\".\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "        \n",
    "        # Ordenar los registros en función del DateTime, esto es, cronológicamente\n",
    "        df = df.sort_values(by= \"DateTime\")\n",
    "        \n",
    "        # Convertir columna de fecha en índice\n",
    "        df = df.set_index(\"DateTime\")\n",
    "        \n",
    "        # Castear los valores de las cotizaciones a tipo \"float\"\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].astype(\"float64\")\n",
    "    \n",
    "        # Eliminar filas con índices duplicados, manteniendo solo la primera entrada/cotización\n",
    "        df = df[~df.index.duplicated(keep=\"first\")]\n",
    "        \n",
    "        return df\n",
    "      \n",
    "    # Carga del fichero de la criptomoneda cuyo valor ha de precedirse\n",
    "    crypto_file = crypto_list[0]\n",
    "    df_crypto = load_crypto(df_crypto, crypto_file)\n",
    " \n",
    "    # Eliminar filas con índices duplicados, manteniendo solo la primera entrada/cotización\n",
    "    df_crypto = df_crypto[~df_crypto.index.duplicated(keep=\"first\")]                          \n",
    "\n",
    "    # Modificación del título de las columnas para el índice S&P 500\n",
    "    SP500_columns_names = [\"Base_currency\", \"Type\",\"DateTime\", \"Date\", \"Time\", \"Frequency\" ,\"Month\", \"Day\", \"SP500_Open\",  \"SP500_High\",\n",
    "                            \"SP500_Low\", \"SP500_Close\", \"SP500_Volume_USD\", \"SP500_Trades\", \"Audit_Time\", \"Symbol\", \"Year\"]\n",
    "    df_SP500.columns = SP500_columns_names\n",
    "    # Modificación del título de las columnas para el índice Nikkei-225\n",
    "    Nikkei_columns_names = [\"Base_currency\", \"Type\",\"DateTime\", \"Date\", \"Time\", \"Frequency\" ,\"Month\", \"Day\", \"Nikkei_Open\",  \"Nikkei_High\",\n",
    "                            \"Nikkei_Low\", \"Nikkei_Close\", \"Nikkei_Volume_USD\", \"Nikkei_Trades\", \"Audit_Time\", \"Symbol\", \"Year\"]\n",
    "    df_Nikkei.columns = Nikkei_columns_names\n",
    "    # Modificación del título de las columnas para el índice IBEX-35\n",
    "    IBEX35_columns_names = [\"Base_currency\", \"Type\",\"DateTime\", \"Date\", \"Time\", \"Frequency\" ,\"Month\", \"Day\", \"IBEX35_Open\",  \"IBEX35_High\",\n",
    "                            \"IBEX35_Low\", \"IBEX35_Close\", \"IBEX35_Volume_USD\", \"IBEX35_Trades\", \"Audit_Time\", \"Symbol\", \"Year\"]\n",
    "    df_IBEX35.columns = IBEX35_columns_names\n",
    "    # Modificación del título de las columnas para el índice NASDAQ-100\n",
    "    Nasdaq_columns_names = [\"Base_currency\", \"Type\",\"DateTime\", \"Date\", \"Time\", \"Frequency\" ,\"Month\", \"Day\", \"Nasdaq_Open\",  \"Nasdaq_High\",\n",
    "                            \"Nasdaq_Low\", \"Nasdaq_Close\", \"Nasdaq_Volume_USD\", \"Nasdaq_Trades\", \"Audit_Time\", \"Symbol\", \"Year\"]\n",
    "    df_Nasdaq.columns = Nasdaq_columns_names    \n",
    "    # Modificación del título de las columnas para el índice DAX (Alemania)\n",
    "    DAX_columns_names = [\"Base_currency\", \"Type\",\"DateTime\", \"Date\", \"Time\", \"Frequency\" ,\"Month\", \"Day\", \"DAX_Open\",  \"DAX_High\",\n",
    "                            \"DAX_Low\", \"DAX_Close\", \"DAX_Volume_USD\", \"DAX_Trades\", \"Audit_Time\", \"Symbol\", \"Year\"]\n",
    "    df_DAX.columns = DAX_columns_names\n",
    "\n",
    "    # Seleccionar únicamente las columnas que necesitamos\n",
    "    df_SP500 = df_SP500.iloc[:, [3,4,11]] \n",
    "    df_Nikkei = df_Nikkei.iloc[:, [3,4,11]]\n",
    "    df_IBEX35 = df_IBEX35.iloc[:, [3,4,11]]\n",
    "    df_Nasdaq = df_Nasdaq.iloc[:, [3,4,11]]\n",
    "    df_DAX = df_DAX.iloc[:, [3,4,11]]\n",
    "  \n",
    "    # Eliminar primera fila, correspondiente al encabezado por defecto.\n",
    "    df_SP500 = df_SP500.drop(index=0).reset_index(drop=True)\n",
    "    df_Nikkei = df_Nikkei.drop(index=0).reset_index(drop=True)\n",
    "    df_IBEX35 = df_IBEX35.drop(index=0).reset_index(drop=True)\n",
    "    df_Nasdaq = df_Nasdaq.drop(index=0).reset_index(drop=True)\n",
    "    df_DAX = df_DAX.drop(index=0).reset_index(drop=True)    \n",
    "\n",
    "    # Concatenar las columnas \"Date\" y \"Time\", para hacer cuadrar la estructura de los datos de fecha con la del resto de datasets\n",
    "    df_SP500[\"DateTime\"] = pd.to_datetime(df_SP500[\"Date\"] + ' ' + df_SP500[\"Time\"])    \n",
    "    df_Nikkei[\"DateTime\"] = pd.to_datetime(df_Nikkei[\"Date\"] + ' ' + df_Nikkei[\"Time\"])\n",
    "    df_IBEX35[\"DateTime\"] = pd.to_datetime(df_IBEX35[\"Date\"] + ' ' + df_IBEX35[\"Time\"])\n",
    "    df_Nasdaq[\"DateTime\"] = pd.to_datetime(df_Nasdaq[\"Date\"] + ' ' + df_Nasdaq[\"Time\"])\n",
    "    df_DAX[\"DateTime\"] = pd.to_datetime(df_DAX[\"Date\"] + ' ' + df_DAX[\"Time\"])\n",
    " \n",
    "    # Eliminar las columnas Date y Time, que ya no vamos a utilizar\n",
    "    df_SP500 = df_SP500[[\"DateTime\", \"SP500_Close\"]]\n",
    "    df_Nikkei = df_Nikkei[[\"DateTime\", \"Nikkei_Close\"]]\n",
    "    df_IBEX35 = df_IBEX35[[\"DateTime\", \"IBEX35_Close\"]]\n",
    "    df_Nasdaq = df_Nasdaq[[\"DateTime\", \"Nasdaq_Close\"]]\n",
    "    df_DAX = df_DAX[[\"DateTime\", \"DAX_Close\"]]\n",
    "  \n",
    "    # Convertir columnas de fecha en índices\n",
    "    df_SP500 = df_SP500.set_index(\"DateTime\")\n",
    "    df_Nikkei = df_Nikkei.set_index(\"DateTime\")\n",
    "    df_IBEX35 = df_IBEX35.set_index(\"DateTime\")\n",
    "    df_Nasdaq = df_Nasdaq.set_index(\"DateTime\")\n",
    "    df_DAX = df_DAX.set_index(\"DateTime\")\n",
    "\n",
    "    # Castear valores a flotantes\n",
    "    df_SP500.iloc[:, 0] = df_SP500.iloc[:, 0].astype(\"float64\")\n",
    "    df_Nikkei.iloc[:, 0] = df_Nikkei.iloc[:, 0].astype(\"float64\")\n",
    "    df_IBEX35.iloc[:, 0] = df_IBEX35.iloc[:, 0].astype(\"float64\")\n",
    "    df_Nasdaq.iloc[:, 0] = df_Nasdaq.iloc[:, 0].astype(\"float64\")\n",
    "    df_DAX.iloc[:, 0] = df_DAX.iloc[:, 0].astype(\"float64\")\n",
    " \n",
    "    # Desindexar la columna DateTime para limpiarla y darle formato de fecha\n",
    "    df_SP500 = df_SP500.reset_index()\n",
    "    df_Nikkei = df_Nikkei.reset_index()\n",
    "    df_IBEX35 = df_IBEX35.reset_index()\n",
    "    df_Nasdaq = df_Nasdaq.reset_index()\n",
    "    df_DAX = df_DAX.reset_index()\n",
    "\n",
    "    # Dar formato de fecha a la columna DateTime\n",
    "    df_SP500[\"DateTime\"] = pd.to_datetime(df_SP500[\"DateTime\"], format = \"%Y-%m-%d %H:%M:%S\")    \n",
    "    df_Nikkei[\"DateTime\"] = pd.to_datetime(df_Nikkei[\"DateTime\"], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_IBEX35[\"DateTime\"] = pd.to_datetime(df_IBEX35[\"DateTime\"], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_Nasdaq[\"DateTime\"] = pd.to_datetime(df_Nasdaq[\"DateTime\"], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_DAX[\"DateTime\"] = pd.to_datetime(df_DAX[\"DateTime\"], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "   \n",
    "    # Reindexar la columna DateTime\n",
    "    df_SP500 = df_SP500.set_index(\"DateTime\")    \n",
    "    df_Nikkei = df_Nikkei.set_index(\"DateTime\")\n",
    "    df_IBEX35 = df_IBEX35.set_index(\"DateTime\")\n",
    "    df_Nasdaq = df_Nasdaq.set_index(\"DateTime\")\n",
    "    df_DAX = df_DAX.set_index(\"DateTime\")\n",
    "\n",
    "    # Fusión de los datasets de las variables predictoras en función de la columna \"DateTime\", incluyendo temnporalmente el dataset del Bitcoin, para poder hacer ffill y bfill del Nikkei basado en el índice de fechas de la criptomoneda.\n",
    "    df_predictors = (\n",
    "        df_crypto\n",
    "        .merge(df_SP500, how=\"left\", on=\"DateTime\")\n",
    "        .merge(df_Nikkei, how=\"left\", on=\"DateTime\")\n",
    "        .merge(df_IBEX35, how=\"left\", on=\"DateTime\")\n",
    "        .merge(df_Nasdaq, how=\"left\", on=\"DateTime\")        \n",
    "        .merge(df_DAX, how=\"left\", on=\"DateTime\")\n",
    "    )\n",
    "\n",
    "    # Bucle para rellenar los valores faltantes en las variables, replicando el primer valor posterior disponible si hay valores faltantes al inicio del dataframe o el valor anterior disponible. \n",
    "    for col in df_predictors.columns:\n",
    "        df_predictors[col] = df_predictors[col].fillna(method = \"bfill\").fillna(method = \"ffill\")\n",
    "\n",
    "    # Eliminamos del dataframe la columna de Bitcoin, ya que es la variable que se debe predecir y no una predictora.\n",
    "    df_predictors = df_predictors.drop(columns=\"XBTUSD_Close\")\n",
    "\n",
    "    # Definición del escalador\n",
    "    sc_X = StandardScaler()\n",
    "    # Escalado de los valores de las variables predictoras\n",
    "    nn_predictors_sc = sc_X.fit_transform(df_predictors)\n",
    "\n",
    "    # Predicciones con el modelo de regresión lineal múltiple cargado\n",
    "    nn_predictions = model.predict(nn_predictors_sc)\n",
    "\n",
    "    # Convertir la serie a Dataframe y renombrar la columna.\n",
    "    df_px_pred = pd.DataFrame(nn_predictions)\n",
    "    df_px_pred = df_px_pred.rename(columns = {0:\"XBTUSD_Close_prediction\"})   \n",
    "\n",
    "\n",
    "    \"\"\"ESTRATEGIA DE TRADING\"\"\"\n",
    "\n",
    "    # Convertir las columnas a tipo numérico\n",
    "    df_px_pred[\"XBTUSD_Close_prediction\"] = pd.to_numeric(df_px_pred[\"XBTUSD_Close_prediction\"], errors='coerce')\n",
    "    df_crypto[\"XBTUSD_Close\"] = pd.to_numeric(df_crypto[\"XBTUSD_Close\"], errors='coerce')\n",
    "\n",
    "    # Creación de variables necesarias para la operativa.\n",
    "    open_position = False\n",
    "    purchase_price = 0\n",
    "    last_signal = 0\n",
    "    \n",
    "    # Lista para almacenar las señales\n",
    "    signals = []\n",
    "    \n",
    "    # Definir los porcentajes de stop loss y take profit\n",
    "    stop_loss_pct = 0.05  # Venta automática si se genera un 5% de pérdida\n",
    "    take_profit_pct = 0.10  # Venta automática si se genera un 10% de beneficio\n",
    "    \n",
    "    for i, prediction in enumerate(df_px_pred[\"XBTUSD_Close_prediction\"]):\n",
    "        # Verificar si el dataframe que contiene las cotizaciones reales tiene suficientes filas\n",
    "        if i >= len(df_crypto):\n",
    "            # Terminar el bucle si el dataframe es más corto.\n",
    "            break  \n",
    "    \n",
    "        # Definir variable para el precio predicho en el intervalo anterior\n",
    "        current_price = df_px_pred[\"XBTUSD_Close_prediction\"].iloc[i-1]\n",
    "    \n",
    "        # Asegurarse de que no hay valores faltantes antes de hacer la comparación\n",
    "        if pd.notna(prediction) and pd.notna(current_price):\n",
    "            # Condición para comprar\n",
    "            if not open_position and prediction > current_price:\n",
    "                # Señal de compra\n",
    "                signals.append(1)\n",
    "                purchase_price = current_price\n",
    "                open_position = True\n",
    "            # Condición para vender (stop loss o take profit)\n",
    "            elif open_position:\n",
    "                # Stop loss: si el precio cae más de un 5% desde la compra\n",
    "                if current_price <= purchase_price * (1 - stop_loss_pct):\n",
    "                    # Señal de venta\n",
    "                    signals.append(0)\n",
    "                    open_position = False\n",
    "                # Take profit: si el precio sube más de un 10% desde la compra\n",
    "                elif current_price >= purchase_price * (1 + take_profit_pct):\n",
    "                    # Señal de venta\n",
    "                    signals.append(0)\n",
    "                    open_position = False\n",
    "                else:\n",
    "                    # Mantener la posición de compra si no se cumplen las condiciones de venta\n",
    "                    signals.append(1)\n",
    "            else:\n",
    "                # No hay posición abierta y no hay señal de compra\n",
    "                signals.append(0)\n",
    "        else:\n",
    "            # Manejar los casos en los que no hay acción de compraventa\n",
    "            signals.append(0)\n",
    "    \n",
    "    # Ajustar señales a la longitud del dataframe de cotizaciones reales de la criptomoneda, en caso de desajuste.\n",
    "    if len(signals) < len(df_crypto):\n",
    "        # Rellenar con 0 (sin acción) si faltan señales\n",
    "        signals.extend([0] * (len(df_crypto) - len(signals)))\n",
    "    \n",
    "    # Crear dataframe de salida\n",
    "    df_outputs = pd.DataFrame({\n",
    "        \"DATETIME\": pd.to_datetime(df_crypto.index),\n",
    "        \"CLOSE\": df_crypto[\"XBTUSD_Close\"],\n",
    "        \"SIGNAL\": signals[:len(df_crypto)]\n",
    "    })\n",
    "    \n",
    "    # Eliminar el índice (fechas), por requerimiento de la función de evaluación del modelo (eval_model)\n",
    "    df_outputs = df_outputs.reset_index(drop=True)\n",
    "\n",
    "    # Mostrar el dataframe de salida\n",
    "    return df_outputs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
